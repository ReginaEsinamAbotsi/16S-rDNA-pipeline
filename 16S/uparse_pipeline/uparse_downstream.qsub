#!/bin/bash
#PBS -N uparse_downtream_20151002
#PBS -S /bin/bash
#PBS -q UCTlong
#PBS -l nodes=1:series600:ppn=4
#PBS -V
#PBS -M gerrit.botha@uct.ac.za
#PBS -d /scratch/researchdata/cbio/medmicbio/project08/process/team/gerrit/runs/20151002/16S/uparse/logs
#PBS -m abe

source /home/gerrit/activate_qiime.sh
inDir=/scratch/researchdata/cbio/medmicbio/project08/process/team/gerrit/runs/20151002/16S/uparse/filtered_fastas/
outDir=/scratch/researchdata/cbio/medmicbio/project08/process/team/gerrit/runs/20151002/16S/uparse/uparse_downstream/
cat $inDir/*filtered_3.fasta > $outDir/filtered_all.fa # Katie added some primer stripping and trancation steps. The output of all those steps are written to the output dir. We just need the input from the last step.

#derep fullength workaround:
cat $outDir/filtered_all.fa | grep -v "^>" | grep -v [^ACGTacgt] | sort -d | uniq -c | while read abundance sequence ; do hash=$(printf "${sequence}" | sha1sum); hash=${hash:0:40};printf ">%s;size=%d;\n%s\n" "${hash}" "${abundance}" "${sequence}"; done > $outDir/filtered_all.uniques.fa 2> $outDir/filtered_all.uniques.fa.e

usearch10 -sortbysize $outDir/filtered_all.uniques.fa -fastaout $outDir/filtered_all.uniques.sorted.fa -minsize 2
usearch10 -cluster_otus $outDir/filtered_all.uniques.sorted.fa -otus $outDir/otus_repsetOUT.fa -relabel OTU_

#usearch global workaround:
mkdir $outDir/split_files
cd $outDir/split_files

#In split_files, break the FASTA files into 100 equal parts:
perl /opt/exp_soft/qiime/packages/other/fasta-splitter.pl -n-parts-total 100 $outDir/filtered_all.fa -out-dir 
for i in $(ls $outDir/split_files/*.fa); do usearch10 -usearch_global $i -db $outDir/otus_repsetOUT.fa  -id 0.97 -strand plus -uc $i.map.uc; done 

#And combine all the map.uc files together
cat $outDir/split_files/*.map.uc > $outDir/otus_mappedOUT.uc

#generate .txt otu file
uc2otutab.py $outDir/otus_mappedOUT.uc > $outDir/otus_table.tab.txt
